# .github/ISSUE_TEMPLATE/unit_test_task.yml
name: "Unit Tests"
description: Minimal, behavior-focused pytest tests (no internals, no spam)
title: "tests: <module>"
labels: [ "tests", "unit" ]

body:
  - type: markdown
    attributes:
      value: |
        ## ⚠️ CRITICAL RULE: NO SOURCE CODE MODIFICATIONS ⚠️
        
        **This is a TEST-ONLY task. NEVER modify ANY source code (src/, packages/*/src/).**
        
        **If source code behavior is unclear or seems wrong:**
        - ❌ **DO NOT** modify src/ 
        - ❌ **DO NOT** fix bugs
        - Option 1: **Know the intended behavior?** → Write tests for the CORRECT behavior (tests may fail, that's OK)
        - Option 2: **Don't know what it should do?** → Write NO tests. Document shortly in 1 - 3 sentences why and close the issue.
        
        **Modify:** test files, `tests/fixtures/`, `tests/conftest.py`, `tests/data/`
        IF Necessary write some short documentation in `docs/` or `README.md`
        but only if its something that definitely needs to be documented and only write short text.
        
        **PRs that touch src/ will be REJECTED.**
        
        ---
        
        ## Unit Test Task - Implementation Guide
        
        **How to write tests:**
        - Create test file in appropriate location (NOT under src/)
        - Package tests: `packages/<name>/tests/unit/test_*.py`
        - Root tests: `tests/unit/**/test_*.py`
        - Test PUBLIC API only - no private methods/attributes
        - Keep tests minimal: ≤5 tests per file, ≤20 lines per test
        
        **Test structure:**
        - Use descriptive test function names: `test_<behavior>_<condition>`
        - Use `@pytest.mark.parametrize` to compress similar cases
        - Prefer Fakes/DI over mocks; use pytest monkeypatch for env/globals
        
        **Fixtures - CRITICAL RULES:**
        - **NEVER create fixtures in test files** - they belong in central locations
        - **ALWAYS check existing fixtures FIRST:** `uv run -m pytest --fixtures`
        - **SEARCH tests/fixtures/ directory** before creating anything new
        - **Fixtures belong in:**
          - `tests/fixtures/<domain>.py` for reusable fixtures (preferred)
          - `tests/conftest.py` for workspace-wide fixtures
          - `packages/<name>/tests/conftest.py` for package-specific fixtures
        - **Reuse existing fixtures:** `tmp_path`, `monkeypatch`, `sample_*`, `mock_*`, `empty_*`
        - **Name new fixtures:** `mock_*`, `sample_*`, `tmp_*`, `empty_*`, `*_factory`
        - **PRs with duplicate/non-centralized fixtures will be REJECTED**
        
        **What to test:**
        - Input → output behavior with different valid inputs
        - Invariants and business rules
        - Exactly ONE negative/error case per file
        - Edge cases IF relevant; DO NOT ADD trivial cases
        - **Test the INTENDED behavior, even if src/ currently doesn't implement it correctly**
        
        **What NOT to test:**
        - Private implementation details (methods starting with _)
        - Exact error messages
        - Exact values that are likely to change
        
        **Test isolation:**
        - No network I/O - mock or fake external calls
        - No real filesystem - use tmp_path fixture
        - Deterministic results - use fixed seeds/time
        - Each test should be independent
        
        **Quality gates (must pass):**
        - `uv run ruff check .` - no warnings
        - `uv run mypy .` - no errors
        - **No changes to any files in src/ or packages/*/src/**
        
        **Issue is DONE when:**
        - Tests written in correct location (tests/ only, NOT src/)
        - Existing fixtures checked and reused where possible
        - New fixtures placed in tests/fixtures/ or conftest.py (NOT in test files)
        - **NO source code files were modified**
        - OR: Documented why tests cannot be written and issue closed

  - type: input
    id: target
    attributes:
      label: Target module
      description: Module to test (e.g., open_ticket_ai.core.config.config_loader)
      placeholder: package.module

  - type: textarea
    id: behaviors
    attributes:
      label: Behaviors to Test
      description: What behaviors need test coverage? Include 1 error case
      placeholder: |
        - Load valid YAML config and return AppConfig
        - Handle missing config file (FileNotFoundError)
        - Validate config schema with Pydantic
        
        NOTE: If unclear what the code should do, write NO tests and document in a few sentences why.

  - type: textarea
    id: implementation-plan
    attributes:
      label: Implementation Plan
      description: Test file location, fixtures needed, parametrized cases?
      placeholder: |
        File: tests/unit/core/config/test_config_loader.py
        
        Check existing fixtures: uv run -m pytest --fixtures
        Search: tests/fixtures/ directory
        
        Reuse or create centralized fixtures in tests/fixtures/<domain>.py
        
        Tests:
        - test_load_valid_config (parametrize valid variations)
        - test_load_missing_file (FileNotFoundError)
        
        FILES TO MODIFY: test files, tests/fixtures/, tests/conftest.py ONLY
        FILES FORBIDDEN: src/**, packages/*/src/**

  - type: textarea
    id: additional-context
    attributes:
      label: Additional Context
      description: Special considerations, dependencies to mock, test data needed
      placeholder: |
        Check existing fixtures before creating new ones:
        uv run -m pytest --fixtures | grep <keyword>
